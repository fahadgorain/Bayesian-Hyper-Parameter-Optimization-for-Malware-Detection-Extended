{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ember\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import json\n",
    "from timeit import default_timer as timer\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "from hyperopt import Trials\n",
    "from hyperopt import fmin\n",
    "#_ = alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Volumes/mac_hdd/DatasetNew/dataset_malwares.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>e_magic</th>\n",
       "      <th>e_cblp</th>\n",
       "      <th>e_cp</th>\n",
       "      <th>e_crlc</th>\n",
       "      <th>e_cparhdr</th>\n",
       "      <th>e_minalloc</th>\n",
       "      <th>e_maxalloc</th>\n",
       "      <th>e_ss</th>\n",
       "      <th>e_sp</th>\n",
       "      <th>...</th>\n",
       "      <th>SectionMaxChar</th>\n",
       "      <th>SectionMainChar</th>\n",
       "      <th>DirectoryEntryImport</th>\n",
       "      <th>DirectoryEntryImportSize</th>\n",
       "      <th>DirectoryEntryExport</th>\n",
       "      <th>ImageDirectoryEntryExport</th>\n",
       "      <th>ImageDirectoryEntryImport</th>\n",
       "      <th>ImageDirectoryEntryResource</th>\n",
       "      <th>ImageDirectoryEntryException</th>\n",
       "      <th>ImageDirectoryEntrySecurity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VirusShare_a878ba26000edaac5c98eff4432723b3</td>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>3758096608</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54440</td>\n",
       "      <td>77824</td>\n",
       "      <td>73728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VirusShare_ef9130570fddc174b312b2047f5f4cf0</td>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>3791650880</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>262276</td>\n",
       "      <td>294912</td>\n",
       "      <td>0</td>\n",
       "      <td>346112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VirusShare_ef84cdeba22be72a69b198213dada81a</td>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>3221225536</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36864</td>\n",
       "      <td>40960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VirusShare_6bf3608e60ebc16cbcff6ed5467d469e</td>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>3224371328</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>356352</td>\n",
       "      <td>1003520</td>\n",
       "      <td>0</td>\n",
       "      <td>14109472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VirusShare_2cc94d952b2efb13c7d6bbe0dd59d3fb</td>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>...</td>\n",
       "      <td>3227516992</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61440</td>\n",
       "      <td>73728</td>\n",
       "      <td>0</td>\n",
       "      <td>90624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Name  e_magic  e_cblp  e_cp  e_crlc  \\\n",
       "0  VirusShare_a878ba26000edaac5c98eff4432723b3    23117     144     3       0   \n",
       "1  VirusShare_ef9130570fddc174b312b2047f5f4cf0    23117     144     3       0   \n",
       "2  VirusShare_ef84cdeba22be72a69b198213dada81a    23117     144     3       0   \n",
       "3  VirusShare_6bf3608e60ebc16cbcff6ed5467d469e    23117     144     3       0   \n",
       "4  VirusShare_2cc94d952b2efb13c7d6bbe0dd59d3fb    23117     144     3       0   \n",
       "\n",
       "   e_cparhdr  e_minalloc  e_maxalloc  e_ss  e_sp  ...  SectionMaxChar  \\\n",
       "0          4           0       65535     0   184  ...      3758096608   \n",
       "1          4           0       65535     0   184  ...      3791650880   \n",
       "2          4           0       65535     0   184  ...      3221225536   \n",
       "3          4           0       65535     0   184  ...      3224371328   \n",
       "4          4           0       65535     0   184  ...      3227516992   \n",
       "\n",
       "   SectionMainChar  DirectoryEntryImport  DirectoryEntryImportSize  \\\n",
       "0                0                     7                       152   \n",
       "1                0                    16                       311   \n",
       "2                0                     6                       176   \n",
       "3                0                     8                       155   \n",
       "4                0                     2                        43   \n",
       "\n",
       "   DirectoryEntryExport  ImageDirectoryEntryExport  ImageDirectoryEntryImport  \\\n",
       "0                     0                          0                      54440   \n",
       "1                     0                          0                     262276   \n",
       "2                     0                          0                      36864   \n",
       "3                     0                          0                     356352   \n",
       "4                     0                          0                      61440   \n",
       "\n",
       "   ImageDirectoryEntryResource  ImageDirectoryEntryException  \\\n",
       "0                        77824                         73728   \n",
       "1                       294912                             0   \n",
       "2                        40960                             0   \n",
       "3                      1003520                             0   \n",
       "4                        73728                             0   \n",
       "\n",
       "   ImageDirectoryEntrySecurity  \n",
       "0                            0  \n",
       "1                       346112  \n",
       "2                            0  \n",
       "3                     14109472  \n",
       "4                        90624  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19611 entries, 0 to 19610\n",
      "Data columns (total 79 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Name                          19611 non-null  object \n",
      " 1   e_magic                       19611 non-null  int64  \n",
      " 2   e_cblp                        19611 non-null  int64  \n",
      " 3   e_cp                          19611 non-null  int64  \n",
      " 4   e_crlc                        19611 non-null  int64  \n",
      " 5   e_cparhdr                     19611 non-null  int64  \n",
      " 6   e_minalloc                    19611 non-null  int64  \n",
      " 7   e_maxalloc                    19611 non-null  int64  \n",
      " 8   e_ss                          19611 non-null  int64  \n",
      " 9   e_sp                          19611 non-null  int64  \n",
      " 10  e_csum                        19611 non-null  int64  \n",
      " 11  e_ip                          19611 non-null  int64  \n",
      " 12  e_cs                          19611 non-null  int64  \n",
      " 13  e_lfarlc                      19611 non-null  int64  \n",
      " 14  e_ovno                        19611 non-null  int64  \n",
      " 15  e_oemid                       19611 non-null  int64  \n",
      " 16  e_oeminfo                     19611 non-null  int64  \n",
      " 17  e_lfanew                      19611 non-null  int64  \n",
      " 18  Machine                       19611 non-null  int64  \n",
      " 19  NumberOfSections              19611 non-null  int64  \n",
      " 20  TimeDateStamp                 19611 non-null  int64  \n",
      " 21  PointerToSymbolTable          19611 non-null  int64  \n",
      " 22  NumberOfSymbols               19611 non-null  int64  \n",
      " 23  SizeOfOptionalHeader          19611 non-null  int64  \n",
      " 24  Characteristics               19611 non-null  int64  \n",
      " 25  Magic                         19611 non-null  int64  \n",
      " 26  MajorLinkerVersion            19611 non-null  int64  \n",
      " 27  MinorLinkerVersion            19611 non-null  int64  \n",
      " 28  SizeOfCode                    19611 non-null  int64  \n",
      " 29  SizeOfInitializedData         19611 non-null  int64  \n",
      " 30  SizeOfUninitializedData       19611 non-null  int64  \n",
      " 31  AddressOfEntryPoint           19611 non-null  int64  \n",
      " 32  BaseOfCode                    19611 non-null  int64  \n",
      " 33  ImageBase                     19611 non-null  int64  \n",
      " 34  SectionAlignment              19611 non-null  int64  \n",
      " 35  FileAlignment                 19611 non-null  int64  \n",
      " 36  MajorOperatingSystemVersion   19611 non-null  int64  \n",
      " 37  MinorOperatingSystemVersion   19611 non-null  int64  \n",
      " 38  MajorImageVersion             19611 non-null  int64  \n",
      " 39  MinorImageVersion             19611 non-null  int64  \n",
      " 40  MajorSubsystemVersion         19611 non-null  int64  \n",
      " 41  MinorSubsystemVersion         19611 non-null  int64  \n",
      " 42  SizeOfHeaders                 19611 non-null  int64  \n",
      " 43  CheckSum                      19611 non-null  int64  \n",
      " 44  SizeOfImage                   19611 non-null  int64  \n",
      " 45  Subsystem                     19611 non-null  int64  \n",
      " 46  DllCharacteristics            19611 non-null  int64  \n",
      " 47  SizeOfStackReserve            19611 non-null  int64  \n",
      " 48  SizeOfStackCommit             19611 non-null  int64  \n",
      " 49  SizeOfHeapReserve             19611 non-null  int64  \n",
      " 50  SizeOfHeapCommit              19611 non-null  int64  \n",
      " 51  LoaderFlags                   19611 non-null  int64  \n",
      " 52  NumberOfRvaAndSizes           19611 non-null  int64  \n",
      " 53  Malware                       19611 non-null  int64  \n",
      " 54  SuspiciousImportFunctions     19611 non-null  int64  \n",
      " 55  SuspiciousNameSection         19611 non-null  int64  \n",
      " 56  SectionsLength                19611 non-null  int64  \n",
      " 57  SectionMinEntropy             19611 non-null  float64\n",
      " 58  SectionMaxEntropy             19611 non-null  int64  \n",
      " 59  SectionMinRawsize             19611 non-null  int64  \n",
      " 60  SectionMaxRawsize             19611 non-null  int64  \n",
      " 61  SectionMinVirtualsize         19611 non-null  int64  \n",
      " 62  SectionMaxVirtualsize         19611 non-null  int64  \n",
      " 63  SectionMaxPhysical            19611 non-null  int64  \n",
      " 64  SectionMinPhysical            19611 non-null  int64  \n",
      " 65  SectionMaxVirtual             19611 non-null  int64  \n",
      " 66  SectionMinVirtual             19611 non-null  int64  \n",
      " 67  SectionMaxPointerData         19611 non-null  int64  \n",
      " 68  SectionMinPointerData         19611 non-null  int64  \n",
      " 69  SectionMaxChar                19611 non-null  int64  \n",
      " 70  SectionMainChar               19611 non-null  int64  \n",
      " 71  DirectoryEntryImport          19611 non-null  int64  \n",
      " 72  DirectoryEntryImportSize      19611 non-null  int64  \n",
      " 73  DirectoryEntryExport          19611 non-null  int64  \n",
      " 74  ImageDirectoryEntryExport     19611 non-null  int64  \n",
      " 75  ImageDirectoryEntryImport     19611 non-null  int64  \n",
      " 76  ImageDirectoryEntryResource   19611 non-null  int64  \n",
      " 77  ImageDirectoryEntryException  19611 non-null  int64  \n",
      " 78  ImageDirectoryEntrySecurity   19611 non-null  int64  \n",
      "dtypes: float64(1), int64(77), object(1)\n",
      "memory usage: 11.8+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_data = data.drop(['Name', 'Machine', 'TimeDateStamp', 'Malware'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahad/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'Benign'), Text(1, 0, 'Malware')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "ax=sns.countplot(data['Malware'])\n",
    "ax.set_xticklabels(['Benign', 'Malware'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(used_data, data['Malware'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of used features is 75\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of used features is {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM benchmark Classification reports score:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       989\n",
      "           1       0.99      0.99      0.99      2934\n",
      "\n",
      "    accuracy                           0.99      3923\n",
      "   macro avg       0.98      0.98      0.98      3923\n",
      "weighted avg       0.99      0.99      0.99      3923\n",
      "\n",
      "LightGBM accuracy score: 0.986\n",
      "ROC AUC: 0.9791438903515776\n",
      "CPU times: user 2.01 s, sys: 37.6 ms, total: 2.05 s\n",
      "Wall time: 289 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# build the new benchmark lightgbm model\n",
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict the results\n",
    "prediction= model.predict(X_test)\n",
    "\n",
    "#evaluation of Classification report SCORE \n",
    "from sklearn.metrics import classification_report\n",
    "print('LightGBM benchmark Classification reports score: ',classification_report(prediction,y_test))\n",
    "#evaluation of accuracy SCORE \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(prediction, y_test)\n",
    "print('LightGBM accuracy score: {0:0.3f}'.format(accuracy_score(prediction,y_test)))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to find the best parameters for Kaggle Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization Primer\n",
    "The problem with grid and random search is that these are uninformed methods because they do not use the past results from different values of hyperparameters in the objective function (remember the objective function takes in the hyperparameters and returns the model cross validation score). We record the results of the objective function for each set of hyperparameters, but the algorithms do not select the next hyperparameter values from this information. Intuitively, if we have the past results, we should use them to reason about what hyperparameter values work the best and choose the next values wisely to try and spend more iterations evaluating promising values. Evaluating hyperparameters in the objective function is very time-consuming, and the concept of Bayesian optimization is to limit calls to the evaluation function by choosing the next hyperparameter values based on the previous results. This allows the algorithm to spend more time evaluating promising hyperparameter values and less time in low-scoring regions of the hyperparameter space\n",
    "\n",
    "\n",
    "Bayesian optimization works by building a surrogate function (in the form of a probability model) of the objective function  P(score|hyperparameters . The surrogate function is much cheaper to evaluate than the objective, so the algorithm chooses the next values to try in the objective based on maximizing a criterion on the surrogate (usually expected improvement).\n",
    "\n",
    "The surrogate function is based on past evaluation results - pairs of (score, hyperparameter) records - and is continually updated with each objective function evaluation. Bayesian optimization therefore uses Bayesian reasoning: form an initial model (called a prior) and then update it with more evidence. The idea is that as the data accumulates, the surrogate function gets closer and closer to the objective function, and the hyperparameter values that are the best in the surrogate function will also do the best in the objective function. Bayesian optimization methods differ in the algorithm used to build the surrogate function and choose the next hyperparameter values to try. Some of the common choices are Gaussian Process (implemented in Spearmint), Random Forest Regression (in SMAC), and the Tree Parzen Estimator (TPE) in Hyperopt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Four Part of Bayesian Optimization\n",
    "Bayesian hyperparameter optimization requires the same four parts as we implemented in grid and random search:\n",
    "\n",
    "Objective Function: takes in an input (hyperparameters) and returns a score to minimize or maximize (the cross validation score)\n",
    "Domain space: the range of input values (hyperparameters) to evaluate\n",
    "Optimization Algorithm: the method used to construct the surrogate function and choose the next values to evaluate\n",
    "Results: score, value pairs that the algorithm uses to build the surrogate function\n",
    "The only differences are that now our objective function will return a score to minimize (this is just convention in the field of optimization), our domain space will be probability distributions rather than a hyperparameter grid, and the optimization algorithm will be an informed method that uses past results to choose the next hyperparameter values to evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperopt\n",
    "Hyperopt is an open-source Python library the implements Bayesian Optimization using the Tree Parzen Estimator algorithm to construct the surrogate function and select the next hyperparameter values to evaluate in the objective function. There are a number of other libraries such as Spearmint (Guassian process surrogate function) and SMAC (random forest regression surrogate function) sharing the same problem structure. The four parts of an optimization problem that we develop here will apply to all the libraries with only a change in syntax. Morevoer, the optimization methods as applied to the Gradient Boosting Machine will translate to other machine learning models or any problem where we have to minimize a function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Machine\n",
    "We will use the gradient booosting machine (GBM) as our model to tune in the LightGBM library.\n",
    "\n",
    "\n",
    "#### Cross Validation with Early Stopping\n",
    "As with random and grid search, we will evaluate each set of hyperparameters using 3 fold cross validation on the training data. The GBM model will be trained with early stopping, where estimators are added to the ensemble until the validation score has not decrease for 100 iterations (estimators added).\n",
    "\n",
    "Cross validation and early stopping will be implemented using the LightGBM cv function. We will use 3 folds and 100 early stopping rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['font.size'] = 18\n",
    "%matplotlib inline\n",
    "\n",
    "# Governing choices for search\n",
    "N_FOLDS = 3\n",
    "MAX_EVALS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The code below reads in the data and creates a training and a set for testing. We can only use the training data a single time when we evaluate the final model. Hyperparameter tuning must be done on the training data using cross validation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (15688, 75)\n",
      "Testing data shape:  (3923, 75)\n",
      "CPU times: user 274 Âµs, sys: 149 Âµs, total: 423 Âµs\n",
      "Wall time: 323 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Testing data shape: ', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model\n",
    "First we can create a model with the default value of hyperparameters and score it using cross validation with early stopping. Using the cv LightGBM function requires creating a Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "# Training set\n",
    "train_set = lgb.Dataset(X_train, label = y_train)\n",
    "test_set = lgb.Dataset(X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fahad/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py:792: UserWarning: silent keyword has been found in `params` and will be ignored.\n",
      "Please use silent argument of the Dataset constructor to pass this parameter.\n",
      "  warnings.warn('{0} keyword has been found in `params` and will be ignored.\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximium ROC AUC in cross validation was 0.996 with std of 0.001.\n",
      "The ideal number of iterations was 136.\n"
     ]
    }
   ],
   "source": [
    "# Default hyperparamters\n",
    "hyperparameters = model.get_params()\n",
    "\n",
    "# Using early stopping to determine number of estimators.\n",
    "del hyperparameters['n_estimators']\n",
    "\n",
    "# Perform cross validation with early stopping\n",
    "cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, metrics = 'auc', \n",
    "           early_stopping_rounds = 100, verbose_eval = False, seed = 42)\n",
    "\n",
    "# Highest score\n",
    "best = cv_results['auc-mean'][-1]\n",
    "\n",
    "# Standard deviation of best score\n",
    "best_std = cv_results['auc-stdv'][-1]\n",
    "\n",
    "print('The maximium ROC AUC in cross validation was {:.3f} with std of {:.3f}.'.format(best, best_std))\n",
    "print('The ideal number of iterations was {}.'.format(len(cv_results['auc-mean'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we can evaluate the baseline model on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The baseline model scores 0.998 ROC AUC on the test set.\n",
      "CPU times: user 2.61 s, sys: 34.5 ms, total: 2.64 s\n",
      "Wall time: 360 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Optimal number of esimators found in cv\n",
    "model.n_estimators = len(cv_results['auc-mean'])\n",
    "\n",
    "# Train and make predicions with model\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict_proba(X_test)[:, 1]\n",
    "baseline_auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "print('The baseline model scores {:.3f} ROC AUC on the test set.'.format(baseline_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function\n",
    "The first part to write is the objective function which takes in a set of hyperparameter values and returns the cross validation score on the training data. An objective function in Hyperopt must return either a single real value to minimize, or a dictionary with a key \"loss\" with the score to minimize (and a key \"status\" indicating if the run was successful or not).\n",
    "\n",
    "## Optimization \n",
    "\n",
    "is typically about minimizing a value, and because our metric is Receiver Operating Characteristic Area Under the Curve (ROC AUC) where higher is better, the objective function will return  1âˆ’ROC AUC Cross Validation . The algorithm will try to drive this value as low as possible (raising the ROC AUC) by choosing the next hyperparameters based on the past results.\n",
    "\n",
    "The complete objective function is shown below. Will be written to a csv file on each call of the function in order to track results as the search progress and so we have a saved record of the search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 Âµs, sys: 1 Âµs, total: 9 Âµs\n",
      "Wall time: 11 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import csv\n",
    "from hyperopt import STATUS_OK\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "def objective(hyperparameters):\n",
    "    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization.\n",
    "       Writes a new line to `outfile` on every iteration\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "    global ITERATION\n",
    "    \n",
    "    ITERATION += 1\n",
    "    \n",
    "    # Using early stopping to find number of trees trained\n",
    "    if 'n_estimators' in hyperparameters:\n",
    "        del hyperparameters['n_estimators']\n",
    "    \n",
    "    # Retrieve the subsample\n",
    "    subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n",
    "    \n",
    "    # Extract the boosting type and subsample to top level keys\n",
    "    hyperparameters['boosting_type'] = hyperparameters['boosting_type']['boosting_type']\n",
    "    hyperparameters['subsample'] = subsample\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n",
    "        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n",
    "\n",
    "    start = timer()\n",
    "    \n",
    "    # Perform n_folds cross validation\n",
    "    cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, \n",
    "                        early_stopping_rounds = 100, metrics = 'auc', seed = 50)\n",
    "\n",
    "    run_time = timer() - start\n",
    "    \n",
    "    # Extract the best score\n",
    "    best_score = cv_results['auc-mean'][-1]\n",
    "    \n",
    "    # Loss must be minimized\n",
    "    loss = 1 - best_score\n",
    "    \n",
    "    # Boosting rounds that returned the highest cv score\n",
    "    n_estimators = len(cv_results['auc-mean'])\n",
    "    \n",
    "    # Add the number of estimators to the hyperparameters\n",
    "    hyperparameters['n_estimators'] = n_estimators\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "    of_connection = open(OUT_FILE, 'a')\n",
    "    writer = csv.writer(of_connection)\n",
    "    writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score])\n",
    "    of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "    return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n",
    "            'train_time': run_time, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain\n",
    "Specifying the domain (called the space in Hyperopt) is a little trickier than in grid search. In Hyperopt, and other Bayesian optimization frameworks, the domian is not a discrete grid but instead has probability distributions for each hyperparameter. For each hyperparameter, we will use the same limits as with the grid, but instead of being defined at each point, the domain represents probabilities for each hyperparameter. This will probably become clearer in the code and the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt.pyll.stochastic import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First we will go through an example of the learning rate. We are using a log-uniform space for the learning rate defined from 0.005 to 0.5. The log - uniform distribution has the values evenly placed in logarithmic space rather than linear space. This is useful for variables that differ over several orders of magnitude such as the learning rate. For example, with a log-uniform distribution, there will be an equal chance of drawing a value from 0.005 to 0.05 and from 0.05 to 0.5 (in linear space far more values would be drawn from the later since the linear distance is much larger. The logarithmic space is exactly the same - a factor of 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58 Âµs, sys: 1e+03 ns, total: 59 Âµs\n",
      "Wall time: 60.3 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create the learning rate\n",
    "learning_rate = {'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can visualize the learning rate by drawing 100000 samples from the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.9 s, sys: 357 ms, total: 22.3 s\n",
      "Wall time: 22.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Density')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "learning_rate_dist = []\n",
    "\n",
    "# Draw 100000 samples from the learning rate domain\n",
    "for _ in range(100000):\n",
    "    learning_rate_dist.append(sample(learning_rate)['learning_rate'])\n",
    "    \n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.kdeplot(learning_rate_dist, color = 'red', linewidth = 2, shade = True);\n",
    "plt.title('Learning Rate Distribution', size = 18); plt.xlabel('Learning Rate', size = 16); plt.ylabel('Density', size = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The number of leaves on the other hand is a discrete uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.6 s, sys: 371 ms, total: 24 s\n",
      "Wall time: 23.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Density')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "# Discrete uniform distribution\n",
    "num_leaves = {'num_leaves': hp.quniform('num_leaves', 128, 512, 1)}\n",
    "num_leaves_dist = []\n",
    "\n",
    "# Sample 100000 times from the number of leaves distribution\n",
    "for _ in range(100000):\n",
    "    num_leaves_dist.append(sample(num_leaves)['num_leaves'])\n",
    "    \n",
    "# kdeplot\n",
    "plt.figure(figsize = (8, 6))\n",
    "sns.kdeplot(num_leaves_dist, linewidth = 2, shade = True);\n",
    "plt.title('Number of Leaves Distribution', size = 18); plt.xlabel('Number of Leaves', size = 16); plt.ylabel('Density', size = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional DomainÂ¶\n",
    "In Hyperopt, we can use nested conditional statements to indicate hyperparameters that depend on other hyperparameters. For example, the \"goss\" boosting_type cannot use subsampling, so when we set up the boosting_type categorical variable, we have to set the subsample to 1.0 while for the other boosting types it's a float between 0.5 and 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 695 Âµs, sys: 96 Âµs, total: 791 Âµs\n",
      "Wall time: 768 Âµs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boosting_type': {'boosting_type': 'goss', 'subsample': 1.0}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# boosting type domain \n",
    "boosting_type = {'boosting_type': hp.choice('boosting_type', \n",
    "                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('subsample', 0.5, 1)}, \n",
    "                                             \n",
    "                                             {'boosting_type': 'goss', 'subsample': 1.0}])}\n",
    "\n",
    "# Draw a sample\n",
    "hyperparams = sample(boosting_type)\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need to set both the boosting_type and subsample as top-level keys in the parameter dictionary. We can use the Python dict.get method with a default value of 1.0. This means that if the key is not present in the dictionary, the value returned will be the default (1.0). One aspect to note is that if boosting_type is goss, then we cannot use subsample (which refers to training on only a fraction of the rows in the training data, a technique known as stochastic gradient boosting). Therefore, we will need a line of logic in our algorithm that sets the subsample to 1.0 (which means use all the rows) if boosting_type=goss. As an example below, if we randomly select a set of hyperparameters, and the boosting type is \"goss\", then we set the subsample to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 Âµs, sys: 0 ns, total: 10 Âµs\n",
      "Wall time: 13.1 Âµs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'goss', 'subsample': 1.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Retrieve the subsample if present otherwise set to 1.0\n",
    "subsample = hyperparams['boosting_type'].get('subsample', 1.0)\n",
    "\n",
    "# Extract the boosting type\n",
    "hyperparams['boosting_type'] = hyperparams['boosting_type']['boosting_type']\n",
    "hyperparams['subsample'] = subsample\n",
    "\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage of nested dictionary with GBM\n",
    "The gbm cannot use the nested dictionary so we need to set the boosting_type and subsample as top level keys.\n",
    "Nested conditionals allow us to use a different set of hyperparameters depending on other hyperparameters. For example, we can explore different models with completely different sets of hyperparameters by using nested conditionals. The only requirement is that the first nested statement must be based on a choice hyperparameter (the choice could be the type of model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Bayesian DomainÂ¶\n",
    "Now we can define the entire domain. Each variable needs to have a label and a few parameters specifying the type and extent of the distribution. For the variables such as boosting type that are categorical, we use the choice variable. Other variables types include quniform, loguniform, and uniform. For the complete list, check out the documentation for Hyperopt. Altogether there are 12 hyperparameters to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 271 Âµs, sys: 8 Âµs, total: 279 Âµs\n",
      "Wall time: 282 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Define the search space\n",
    "space = {'boosting_type': hp.choice('boosting_type', \n",
    "                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n",
    "                                             {'boosting_type': 'goss', 'subsample': 1.0}]),\n",
    "    \n",
    "    'num_leaves': hp.quniform('num_leaves', 128, 1024, 2),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.5)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 200000, 200),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 20, 500, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "   # 'max_depth': hp.randint('max_depth',30),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0),\n",
    "    'feature_fraction': hp.uniform('feature_fraction',0.5, 1.0),\n",
    "    'bagging_fraction': hp.uniform('bagging_fraction',0.5, 1.0),\n",
    "    'is_unbalance': hp.choice('is_unbalance', [True, False]),\n",
    "}\n",
    "space['objective'] = 'binary'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Sampling from the Domain\n",
    "Let's sample from the domain (using the conditional logic) to see the result of each draw. Every time we run this code, the results will change. (Again notice that we need to assign the top level keys to the keywords understood by the GBM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.14 ms, sys: 150 Âµs, total: 1.29 ms\n",
      "Wall time: 1.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.5572292431423053,\n",
       " 'boosting_type': 'goss',\n",
       " 'colsample_bytree': 0.7773335206606876,\n",
       " 'feature_fraction': 0.7250783213497973,\n",
       " 'is_unbalance': True,\n",
       " 'learning_rate': 0.21387833348892415,\n",
       " 'min_child_samples': 175.0,\n",
       " 'num_leaves': 376.0,\n",
       " 'objective': 'binary',\n",
       " 'reg_alpha': 0.7248252367870717,\n",
       " 'reg_lambda': 0.9916391883234061,\n",
       " 'subsample_for_bin': 66400.0,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Sample from the full space\n",
    "x = sample(space)\n",
    "\n",
    "# Conditional logic to assign top-level keys\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 ms, sys: 253 Âµs, total: 1.42 ms\n",
      "Wall time: 1.22 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.5320852954028576,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'colsample_bytree': 0.8600147131958198,\n",
       " 'feature_fraction': 0.8193651763855467,\n",
       " 'is_unbalance': False,\n",
       " 'learning_rate': 0.20448507206249036,\n",
       " 'min_child_samples': 335.0,\n",
       " 'num_leaves': 250.0,\n",
       " 'objective': 'binary',\n",
       " 'reg_alpha': 0.09988079448085196,\n",
       " 'reg_lambda': 0.609372945167202,\n",
       " 'subsample_for_bin': 102600.0,\n",
       " 'subsample': 0.9764691008547826}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "x = sample(space)\n",
    "subsample = x['boosting_type'].get('subsample', 1.0)\n",
    "x['boosting_type'] = x['boosting_type']['boosting_type']\n",
    "x['subsample'] = subsample\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's test the objective function with the domain to make sure it works. (Every time the of_connection line is run, the outfile will be overwritten, so use a different name for each trial to save the results.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validation loss = 0.003.\n",
      "The optimal number of estimators was 565.\n",
      "CPU times: user 23.4 s, sys: 689 ms, total: 24.1 s\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a new file and open a connection\n",
    "OUT_FILE = 'bayes_test.csv'\n",
    "of_connection = open(OUT_FILE, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Write column names\n",
    "headers = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\n",
    "writer.writerow(headers)\n",
    "of_connection.close()\n",
    "\n",
    "# Test the objective function\n",
    "results = objective(sample(space))\n",
    "print('The cross validation loss = {:.3f}.'.format(results['loss']))\n",
    "print('The optimal number of estimators was {}.'.format(results['hyperparameters']['n_estimators']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Optimization Algorithm\n",
    "The optimization algorithm is the method for constructing the surrogate function (probability model) and selecting the next set of hyperparameters to evaluate in the objective function. Hyperopt has two choices: random search and Tree Parzen Estimator.\n",
    "\n",
    "The technical details of TPE can be found in this article(https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf) and a conceptual explanation is in this article(https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f). Although this is the most technical part of Bayesian hyperparameter optimization, defining the algorithm in Hyperopt is simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe\n",
    "\n",
    "# Create the algorithm\n",
    "tpe_algorithm = tpe.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results History\n",
    "The final part is the history of objective function evaluations. Although Hyperopt internally keeps track of the results for the algorithm to use, if we want to monitor the results and have a saved copy of the search, we need to store the results ourselves. Here, we are using two methods to make sure we capture all the results:\n",
    "\n",
    "A Trials object that stores the dictionary returned from the objective function\n",
    "Adding a line to a csv file every iteration.\n",
    "The csv file option also lets us monitor the results of an on-going experiment. Also, do not use Excel to open the file while training is on-going. Instead check the results using tail results/out_file.csv from bash or open the file in Sublime Text or Notepad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27 Âµs, sys: 5 Âµs, total: 32 Âµs\n",
      "Wall time: 35 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from hyperopt import Trials\n",
    "\n",
    "# Record results\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Trials object will hold everything returned from the objective function in the .results attribute. We can use this after the search is complete to inspect the results, but an easier method is to read in the csv file because that will already be in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 323 Âµs, sys: 628 Âµs, total: 951 Âµs\n",
      "Wall time: 465 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create a file and open a connection\n",
    "OUT_FILE = 'bayes_test.csv'\n",
    "of_connection = open(OUT_FILE, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Write column names\n",
    "headers = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score']\n",
    "writer.writerow(headers)\n",
    "of_connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automated Hyperparameter Optimization in Practice\n",
    "We have all four parts we need to run the optimization. To run Bayesian optimization we use the fmin function (a good reminder that we need a metric to minimize!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fmin takes the four parts defined above as well as the maximum number of iterations max_evals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:08<00:00,  2.85s/trial, best loss: 0.0024530347171776157]\n",
      "CPU times: user 1min 4s, sys: 1.26 s, total: 1min 5s\n",
      "Wall time: 8.57 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.711815724242832,\n",
       " 'boosting_type': 0,\n",
       " 'colsample_by_tree': 0.8313299880947302,\n",
       " 'feature_fraction': 0.8198975054031239,\n",
       " 'gdbt_subsample': 0.8175406236294445,\n",
       " 'is_unbalance': 1,\n",
       " 'learning_rate': 0.04587997602440739,\n",
       " 'min_child_samples': 495.0,\n",
       " 'num_leaves': 132.0,\n",
       " 'reg_alpha': 0.0838008024640744,\n",
       " 'reg_lambda': 0.25011502153848253,\n",
       " 'subsample_for_bin': 180200.0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Global variable\n",
    "global  ITERATION\n",
    "\n",
    "ITERATION = 0\n",
    "\n",
    "# Run optimization\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n",
    "            max_evals = MAX_EVALS)\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The best object holds only the hyperparameters that returned the lowest loss in the objective function. Although this is ultimately what we are after, if we want to understand how the search progresses, we need to inspect the Trials object or the csv file. For example, we can sort the results returned from the objective function by the lowest loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 Âµs, sys: 0 ns, total: 17 Âµs\n",
      "Wall time: 19.8 Âµs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.0024530347171776157,\n",
       "  'hyperparameters': {'bagging_fraction': 0.711815724242832,\n",
       "   'boosting_type': 'gbdt',\n",
       "   'colsample_bytree': 0.8313299880947302,\n",
       "   'feature_fraction': 0.8198975054031239,\n",
       "   'is_unbalance': False,\n",
       "   'learning_rate': 0.04587997602440739,\n",
       "   'min_child_samples': 495,\n",
       "   'num_leaves': 132,\n",
       "   'objective': 'binary',\n",
       "   'reg_alpha': 0.0838008024640744,\n",
       "   'reg_lambda': 0.25011502153848253,\n",
       "   'subsample_for_bin': 180200,\n",
       "   'subsample': 0.8175406236294445,\n",
       "   'n_estimators': 523},\n",
       "  'iteration': 3,\n",
       "  'train_time': 2.273612749999984,\n",
       "  'status': 'ok'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Sort the trials with lowest loss (highest AUC) first\n",
    "trials_dict = sorted(trials.results, key = lambda x: x['loss'])\n",
    "trials_dict[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An easier method is to read in the csv file since this will be a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 ms, sys: 193 Âµs, total: 1.45 ms\n",
      "Wall time: 1.39 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = pd.read_csv(OUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The function below takes in the results, trains a model on the training data, and evalutes on the testing data. It returns a dataframe of hyperparameters from the search.\n",
    "\n",
    "## Saving the results :\n",
    "Saving the results to a csv file converts the dictionary of hyperparameters to a string. We need to map this back to a dictionary using ast.literal_eval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 Âµs, sys: 0 ns, total: 4 Âµs\n",
      "Wall time: 7.87 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import ast\n",
    "\n",
    "def evaluate(results, name):\n",
    "    \"\"\"Evaluate model on test data using hyperparameters in results\n",
    "       Return dataframe of hyperparameters\"\"\"\n",
    "    \n",
    "    new_results = results.copy()\n",
    "    # String to dictionary\n",
    "    new_results['hyperparameters'] = new_results['hyperparameters'].map(ast.literal_eval)\n",
    "    \n",
    "    # Sort with best values on top\n",
    "    new_results = new_results.sort_values('score', ascending = False).reset_index(drop = True)\n",
    "    \n",
    "    # Print out cross validation high score\n",
    "    print('The highest cross validation score from {} was {:.3f} found on iteration {}.'.format(name, new_results.loc[0, 'score'], new_results.loc[0, 'iteration']))\n",
    "    \n",
    "    # Use best hyperparameters to create a model\n",
    "    hyperparameters = new_results.loc[0, 'hyperparameters']\n",
    "    model = lgb.LGBMClassifier(**hyperparameters)\n",
    "    \n",
    "    # Train and make predictions\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print('ROC AUC from {} on test data = {:.3f}.'.format(name, roc_auc_score(y_test, preds)))\n",
    "    \n",
    "    # Create dataframe of hyperparameters\n",
    "    hyp_df = pd.DataFrame(columns = list(new_results.loc[0, 'hyperparameters'].keys()))\n",
    "\n",
    "    # Iterate through each set of hyperparameters that were evaluated\n",
    "    for i, hyp in enumerate(new_results['hyperparameters']):\n",
    "        hyp_df = hyp_df.append(pd.DataFrame(hyp, index = [0]), \n",
    "                               ignore_index = True)\n",
    "        \n",
    "    # Put the iteration and score in the hyperparameter dataframe\n",
    "    hyp_df['iteration'] = new_results['iteration']\n",
    "    hyp_df['score'] = new_results['score']\n",
    "    \n",
    "    return hyp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest cross validation score from Bayesian was 0.998 found on iteration 3.\n",
      "ROC AUC from Bayesian on test data = 0.998.\n",
      "CPU times: user 5.4 s, sys: 78.2 ms, total: 5.48 s\n",
      "Wall time: 733 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bagging_fraction</th>\n",
       "      <th>boosting_type</th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>feature_fraction</th>\n",
       "      <th>is_unbalance</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>min_child_samples</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>objective</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>subsample_for_bin</th>\n",
       "      <th>subsample</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>iteration</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.711816</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.831330</td>\n",
       "      <td>0.819898</td>\n",
       "      <td>False</td>\n",
       "      <td>0.045880</td>\n",
       "      <td>495</td>\n",
       "      <td>132</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.083801</td>\n",
       "      <td>0.250115</td>\n",
       "      <td>180200</td>\n",
       "      <td>0.817541</td>\n",
       "      <td>523</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.917292</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.832615</td>\n",
       "      <td>0.637510</td>\n",
       "      <td>False</td>\n",
       "      <td>0.091235</td>\n",
       "      <td>60</td>\n",
       "      <td>796</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.114817</td>\n",
       "      <td>0.189729</td>\n",
       "      <td>179800</td>\n",
       "      <td>0.864005</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608767</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>0.776658</td>\n",
       "      <td>0.912802</td>\n",
       "      <td>False</td>\n",
       "      <td>0.023188</td>\n",
       "      <td>435</td>\n",
       "      <td>456</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.819662</td>\n",
       "      <td>0.240469</td>\n",
       "      <td>173400</td>\n",
       "      <td>0.803805</td>\n",
       "      <td>1044</td>\n",
       "      <td>2</td>\n",
       "      <td>0.997510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bagging_fraction boosting_type  colsample_bytree  feature_fraction  \\\n",
       "0          0.711816          gbdt          0.831330          0.819898   \n",
       "1          0.917292          gbdt          0.832615          0.637510   \n",
       "2          0.608767          gbdt          0.776658          0.912802   \n",
       "\n",
       "  is_unbalance  learning_rate min_child_samples num_leaves objective  \\\n",
       "0        False       0.045880               495        132    binary   \n",
       "1        False       0.091235                60        796    binary   \n",
       "2        False       0.023188               435        456    binary   \n",
       "\n",
       "   reg_alpha  reg_lambda subsample_for_bin  subsample n_estimators  iteration  \\\n",
       "0   0.083801    0.250115            180200   0.817541          523          3   \n",
       "1   0.114817    0.189729            179800   0.864005          111          1   \n",
       "2   0.819662    0.240469            173400   0.803805         1044          2   \n",
       "\n",
       "      score  \n",
       "0  0.997547  \n",
       "1  0.997525  \n",
       "2  0.997510  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "bayes_results = evaluate(results, name = 'Bayesian')\n",
    "bayes_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue OptimizationÂ¶\n",
    "Hyperopt can continue searching where a previous search left off if we pass in a Trials object that already has results. The algorithms used in Bayesian optimization are black-box optimizers because they have no internal state. All they need is the previous results of objective function evaluations (the input values and loss) and they can build up the surrogate function and select the next values to evaluate in the objective function. This means that any search can be continued as long as we have the history in a Trials object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<?, ?trial/s, best loss=?]\n",
      "CPU times: user 5.65 ms, sys: 663 Âµs, total: 6.32 ms\n",
      "Wall time: 5.83 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MAX_EVALS = 3\n",
    "\n",
    "# Continue training\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n",
    "            max_evals = MAX_EVALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To save the Trials object so it can be read in later for more training, we can use the json format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 317 Âµs, sys: 448 Âµs, total: 765 Âµs\n",
      "Wall time: 457 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "# Save the trial results\n",
    "with open('trials.json', 'w') as f:\n",
    "    f.write(json.dumps(trials_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To start the training from where it left off, simply load in the Trials object and pass it to an instance of fmin. (You might even be able to tweak the hyperparameter distribution and continue searching with the Trials object because the algorithm does not maintain an internal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "Now that we have developed all the necessary parts for automated hyperparameter tuning using Bayesian optimization, we can apply these to any dataset or any machine learning method. The functions taken here can be put in a script and run a full dataset. Next, we will go through results from 100 evaluations on  the dataset to see how the search progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I will continue running the Bayesian Hyperparameter optimization for 10310 iterations below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 10310/50000 [6:37:04<25:28:34,  2.31s/trial, best loss: 0.0021537207647738255]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             )\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(hyperparameters)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, train_set, num_boost_round, folds, nfold, stratified, shuffle, metrics, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, fpreproc, verbose_eval, show_stdv, seed, callbacks, eval_train_metric)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                     \u001b[0mend_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_agg_cv_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvfolds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_train_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mhandler_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboosters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandler_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# the run was stopped at 10310 iterations (you can do as many evlauation as needed ) \n",
    "MAX_EVALS = 50000\n",
    "\n",
    "\n",
    "# Create a new file and open a connection\n",
    "OUT_FILE = 'KGD_trials_50000.csv'\n",
    "of_connection = open(OUT_FILE, 'w')\n",
    "writer = csv.writer(of_connection)\n",
    "\n",
    "# Write column names\n",
    "headers = ['loss', 'hyperparameters', 'score']\n",
    "writer.writerow(headers)\n",
    "of_connection.close()\n",
    "\n",
    "# Record results\n",
    "trials = Trials()\n",
    "\n",
    "global ITERATION\n",
    "\n",
    "ITERATION = 0 \n",
    "\n",
    "best = fmin(fn = objective, space = space, algo = tpe.suggest,\n",
    "            trials = trials, max_evals = MAX_EVALS)\n",
    "\n",
    "# Sort the trials with lowest loss (highest AUC) first\n",
    "trials_dict = sorted(trials.results, key = lambda x: x['loss'])\n",
    "\n",
    "print('Finished, best results')\n",
    "print(trials_dict[:1])\n",
    "\n",
    "#Save the trial results\n",
    "with open('trials.json', 'w') as f:\n",
    "    f.write(json.dumps(trials_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "Bayesian optimization is one method for automated hyperparameter tuning. Automated hyperparameter tuning aims to find the best hyperparameter values for a machine learning model on a given dataset with no input from the data scientist beyond initial set-up required. Bayesian optimization uses Bayesian reasoning to build a probability model of the objecitve function  P(score|hyperparameters)  which is then used to select the next hyperparameter values to evaluate. The concept is to use more search iterations evaluating promising hyperparameter values by reasoning from the past results. This is an intuitive method of hyperparamter optimization that works in much the same way a human does to get better at any situation: learn from past experiences! If everything works as expected, Bayesian hyperparameter optimization can result in:\n",
    "\n",
    "1-Better generalization performance on the test set\n",
    "2-Fewer iterations than random or grid search require\n",
    "\n",
    "Even if Bayesian optimization (or other automated hyperparameter tuning methods) does not deliver on the above points in all situations, it is a useful skill to master as a data scientist. In the future, data scientists are not going to spend valuable time tweaking model hyperparameters, and knowing methods for accomplishing this automatically will go a long way in your career or studies!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
